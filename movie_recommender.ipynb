{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Schritt 1: Importieren der Abhängigkeiten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Schritt 2: Laden der Daten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# die Pfade zu den Dateien zu laden\n",
    "movies_path = \"https://raw.githubusercontent.com/andresmorenoviteri/workshops/refs/heads/main/movies.csv\"\n",
    "ratings_path = \"https://raw.githubusercontent.com/andresmorenoviteri/workshops/refs/heads/main/ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(movies_path)\n",
    "ratings_df = pd.read_csv(ratings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Schritt 3: Datenexploration** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = ratings_df.drop('timestamp', axis=1)\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings = len(ratings_df)\n",
    "n_movies = ratings_df[\"movieId\"].nunique()\n",
    "n_users = ratings_df['userId'].nunique()\n",
    "\n",
    "print(f\"number of ratings: {n_ratings}\")\n",
    "print(f\"movies rated: {n_movies}\")\n",
    "print(f\"users: {n_users}\")\n",
    "print(f\"average number of ratings per movie: {round(n_ratings/n_movies, 2)}\")\n",
    "print(f\"average number of ratings per user: {round(n_ratings/n_users, 2)}\") # very high number, not realistic, usually only a couple of ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der Filmbewertungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sind die Bewertungen gleichmäßig verteilt oder in irgendeiner Weise verzerrt?\n",
    "sns.countplot(x='rating', hue='rating', data=ratings_df, palette='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mean global rating: {round(ratings_df['rating'].mean(), 2)}\")\n",
    "\n",
    "mean_rating = ratings_df.groupby('userId')['rating'].mean()\n",
    "print(f\"mean rating per user: {round(mean_rating.mean(), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welche Filme werden am häufigsten bewertet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df['movieId'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings_df = ratings_df.merge(movies_df, how='inner', on='movieId')\n",
    "movie_ratings_df['title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prüfen, ob in den Datensätzen Leerstellen vorhanden sind\n",
    "movie_ratings_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Forrest Gump, Shawshank redemption und Pulp Fiction sind die meistbewerteten Filme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welches sind die am schlechtesten und am besten bewerteten Filme?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stats = movie_ratings_df.groupby('title')['rating'].agg(['count', 'mean']).reset_index()\n",
    "movie_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_rated = movie_stats.loc[movie_stats['mean'].idxmin()]['title']\n",
    "print(f'lowest rated movie: {lowest_rated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_rated = movie_stats.loc[movie_stats['mean'].idxmax()]['title']\n",
    "print(f'highest rated movie: {highest_rated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl der Bewertungen für Salem's Lot überprüfen \n",
    "len(movie_stats[movie_stats['title'] == \"'Salem's Lot (2004)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eine einzige Bewertung reicht nicht aus, um einen hoch bewerteten Film zu erhalten, verwenden Sie den Bayes'schen Durchschnitt, um eine bessere Vorhersage zu erhalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "**Bayesianischer Durchschnitt**\n",
    "\n",
    "Der Bayesianische Durchschnitt ist eine Methode zur Schätzung des Mittelwerts einer Grundgesamtheit unter Verwendung externer Informationen, insbesondere einer bereits bestehenden Überzeugung, die in die Berechnung einfließt.\n",
    "\n",
    "Der Bayesianische Durchschnitt ist definiert als:\n",
    "\n",
    "$x_{i} =  \\frac{C \\times m + \\Sigma{\\text{ratings}}}{C+N}$\n",
    " \n",
    "- $C$ wird auf der Grundlage der Größe des Datensatzes gewählt, in unserem Fall ist es die durchschnittliche Anzahl der Bewertungen für jeden Film.\n",
    "- $m$ ist der vorherige Mittelwert, in unserem Fall also die durchschnittliche Bewertung eines Films.\n",
    "- $N$ ist die Gesamtzahl der Bewertungen für den Film $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = movie_stats['count'].mean()\n",
    "m = movie_stats['mean'].mean()\n",
    "\n",
    "print(f'average number of ratings for a given movie: {round(c, 2)}')\n",
    "print(f'average rating for a given movie: {round(m, 2)}')\n",
    "\n",
    "# create new column with Bayesian averages\n",
    "bayesian_average_list = []\n",
    "for idx, row in movie_stats.iterrows():\n",
    "    x = ((c*m)+(row['count']*row['mean']))/((c)+row['count'])\n",
    "    bayesian_average_list.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stats['bayesian_average'] = bayesian_average_list\n",
    "movie_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stats[movie_stats['title'].str.contains(\"Salem's Lot\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sehen wir, dass „Salem's Lot“ nicht mehr der am besten bewertete Film ist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_min = movie_stats.loc[movie_stats['bayesian_average'].idxmin()]['title']\n",
    "bayesian_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayesian_max = movie_stats.loc[movie_stats['bayesian_average'].idxmax()]['title']\n",
    "bayesian_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stats.sort_values(by='bayesian_average', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die bestbewerteten Filme sind Shawshank Redemption, Godfather und Fight Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die am schlechtesten bewerteten Filme sind Speed 2, Battlefield Earth und Godzilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ein Blick auf Filmgenres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df['genres'] = movies_df['genres'].apply(lambda x : x.split('|'))\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filmgenres zählen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "genres_list = movies_df['genres'].explode()\n",
    "genre_counts = Counter(genres_list)\n",
    "genre_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the 5 most common genres are: {genre_counts.most_common(5)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_counts_df = pd.DataFrame([genre_counts]).T.reset_index()\n",
    "genre_counts_df.columns = ['genre', 'count']\n",
    "\n",
    "sns.barplot(x='genre', y='count', hue='genre', data=genre_counts_df.sort_values(by='count', ascending=False), legend=False, palette='viridis')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Schritt 4: Vorverarbeitung der Daten**\n",
    "\n",
    "Wir werden die Technik der kollaborativen Filterung anwenden, um Empfehlungen für die Benutzer zu erstellen.\n",
    "Die Grundlage für diese Technik ist, dass ähnliche Nutzer einen ähnlichen Filmgeschmack haben.\n",
    "\n",
    "Wir beginnen damit, unsere Daten in eine „Nutzwertmatrix“ umzuwandeln, d. h. eine Matrix aus Nutzern und Objekten. Die Zeilen werden repräsentieren die Nutzer, während die Spalten die Filme darstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_stats['count'][movie_stats['title'] == 'Toy Story (1995)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def create_matrix(df):\n",
    "\n",
    "    rows = df['userId'].nunique()\n",
    "    columns = df['movieId'].nunique()\n",
    "\n",
    "    userMapper = dict(zip(np.unique(df['userId']), list(range(rows))))\n",
    "    movieMapper = dict(zip(np.unique(df['movieId']), list(range(columns))))\n",
    "\n",
    "    invUserMapper = dict(zip(list(range(rows)), np.unique(df['userId'])))\n",
    "    invMovieMapper = dict(zip(list(range(columns)), np.unique(df['movieId'])))\n",
    "\n",
    "    # create the user-item interaction matrix\n",
    "    userMovieMatrix = pd.pivot_table(df, values='rating', index='userId', columns='movieId').fillna(0)\n",
    "    sparseMatrix= csr_matrix(userMovieMatrix)\n",
    "\n",
    "    # convert matrx to sparse matrix\n",
    "    return sparseMatrix, userMapper, movieMapper, invUserMapper, invMovieMapper \n",
    "\n",
    "sparse_matrix, user_mapper, movie_mapper, inv_user_mapper, inv_movie_mapper = create_matrix(movie_ratings_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix.nnz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maß für die Dünnbesetztheit\n",
    "Die Dünnbesetzt wird berechnet, indem die Anzahl der gespeicherten (nicht leeren) Felder durch die Gesamtzahl der Felder geteilt wird. Die Anzahl der gespeicherten Werte in unserer Matrix entspricht der Anzahl der Bewertungen in unserem Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total = sparse_matrix.shape[0] * sparse_matrix.shape[1]\n",
    "num_ratings = sparse_matrix.nnz #csr_matrix.nnz counts the stored values in the sparse matrix. The rest of the cells are empty\n",
    "sparsity = num_ratings / n_total\n",
    "print(f\"Matrix sparsity: {round(sparsity*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das **Kaltstartproblem** tritt auf, wenn es neue Nutzer und Filme gibt, die noch keine Bewertungen haben.\n",
    " \n",
    "In unserem Movielens-Datensatz haben alle Nutzer und Filme mindestens eine Bewertung, aber im Allgemeinen ist es wichtig, zu prüfen, ob Nutzer und Filme wenige oder keine Interventionen haben\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hier wird überprüft, ob alle Zellen im Datensatz nicht leer sind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings_per_user = sparse_matrix.getnnz(axis=1)\n",
    "len(n_ratings_per_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The most active user rated {n_ratings_per_user.max()} movies\")\n",
    "print(f\"The least active user rated {n_ratings_per_user.min()} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ratings_per_movie = sparse_matrix.getnnz(axis=0)\n",
    "len(n_ratings_per_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The most rated movie has {n_ratings_per_movie.max()} ratings\")\n",
    "print(f\"The least rated movie has {n_ratings_per_movie.min()} ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.kdeplot(n_ratings_per_user, fill=True)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Number of ratings per user\", fontsize=14)\n",
    "plt.xlabel(\"number of ratings per user\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.kdeplot(n_ratings_per_movie, fill=True)\n",
    "plt.xlim(0)\n",
    "plt.title(\"Number of ratings per movie\", fontsize=14)\n",
    "plt.xlabel(\"number of ratings per movie\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Schritt 5: Item-Empfehlungen mit *K-Nearest-Neighbor***\n",
    "\n",
    "Wir werden die k Filme finden, die die ähnlichsten Vektoren für das Nutzerengagement für einen Film i haben.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def find_recommended_movies(movieId, sparseMatrix, movieMapper, invMovieMapper, k, metric='cosine'):\n",
    "    # transpose matrix to get movie recommendations from matrix\n",
    "    sparseMatrix = sparseMatrix.T\n",
    "    recommendationIds = []\n",
    "    movieIdx = movieMapper[movieId]\n",
    "    movieVec = sparseMatrix[movieIdx]\n",
    "    if isinstance(movieVec, (np.ndarray)):\n",
    "        movieVec = movieVec.reshape(1, -1)\n",
    "    # use k+1 since knn outputs include the movieId of interest\n",
    "    knn = NearestNeighbors(n_neighbors=k+1, metric=metric, algorithm='brute')\n",
    "    knn.fit(sparseMatrix)\n",
    "    recommendations = knn.kneighbors(movieVec, return_distance=False)\n",
    "    for i in range(0, k):\n",
    "        n = recommendations.item(i)\n",
    "        recommendationIds.append(invMovieMapper[n])\n",
    "    recommendationIds.pop(0)\n",
    "    return recommendationIds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_mapper[33794]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interaktive Grafik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def interactive_visualization(sparseMatrix, movieMapper, invMovieMapper, k, metric='cosine'):\n",
    "    # Transpose sparse matrix\n",
    "    sparseMatrix = sparseMatrix.T\n",
    "\n",
    "    # Normalize before dimensionality reduction\n",
    "    scaler = StandardScaler()\n",
    "    scaledSparseMatrix = scaler.fit_transform(sparseMatrix.toarray())  \n",
    "\n",
    "    # Apply t-SNE for better visualization\n",
    "    tsne = TSNE(n_components=2, perplexity=50, random_state=42)\n",
    "    reducedMatrix = tsne.fit_transform(scaledSparseMatrix)\n",
    "\n",
    "    # Create a DataFrame for visualization\n",
    "    df = pd.DataFrame(reducedMatrix, columns=['PCA1', 'PCA2'])\n",
    "    df['movieId'] = [invMovieMapper[i] for i in range(sparseMatrix.shape[0])]\n",
    "\n",
    "    # Map movieId to titles efficiently\n",
    "    movie_id_to_title = movie_ratings_df.set_index('movieId')['title'].to_dict()\n",
    "    df['title'] = df['movieId'].map(movie_id_to_title)\n",
    "\n",
    "    # Fit KNN for recommendations\n",
    "    knn = NearestNeighbors(n_neighbors=k+1, metric=metric, algorithm='brute')\n",
    "    knn.fit(sparseMatrix)\n",
    "\n",
    "    def get_recommendations(movieId):\n",
    "        movieIdx = movieMapper[movieId]\n",
    "        movieVec = sparseMatrix[movieIdx]\n",
    "        movieVec = movieVec.reshape(1, -1) if isinstance(movieVec, np.ndarray) else movieVec\n",
    "        recommendations = knn.kneighbors(movieVec, return_distance=False)[0][1:]  # Exclude the movie itself\n",
    "        return [invMovieMapper[n] for n in recommendations]\n",
    "\n",
    "    # Generate recommendations\n",
    "    df['recommendations'] = df['movieId'].apply(lambda x: [movie_id_to_title.get(int(i), \"Unknown\") for i in get_recommendations(x)])\n",
    "\n",
    "    # Assign unique color values\n",
    "    df['color'] = range(len(df))\n",
    "\n",
    "    # Create an interactive scatter plot\n",
    "    fig = px.scatter(\n",
    "        df,\n",
    "        x='PCA1',\n",
    "        y='PCA2',\n",
    "        hover_data=['title', 'recommendations'],\n",
    "        title=\"Movie Clusters with Recommendations\",\n",
    "        template='plotly_dark',\n",
    "        color='color',\n",
    "        opacity=0.6\n",
    "    )\n",
    "\n",
    "    # Improve marker visibility\n",
    "    fig.update_traces(marker=dict(size=4, opacity=0.7))\n",
    "    fig.update_layout(clickmode='event+select')\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "# Call the function with appropriate parameters\n",
    "interactive_visualization(sparse_matrix, movie_mapper, inv_movie_mapper, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**find_recommended_movies()** liefert eine Liste von **movieIds**, die dem gewünschten Film am ähnlichsten sind.\n",
    "\n",
    "Wir erstellen ein Wörterbuch, das die **movieId** dem **title** des Films zuordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = find_recommended_movies(33794, sparse_matrix, movie_mapper, inv_movie_mapper, 10) \n",
    "movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aus den gefundenen Indizes, müssen wir diese in die dazu passende movieId umwandeln. \n",
    "print(f\"for the movie {movie_ratings_df['title'].loc[movie_ratings_df['movieId'] == 33794].unique().item()}, the recommendations are:\")\n",
    "for id in movie_titles:\n",
    "    print(movie_ratings_df['title'].loc[movie_ratings_df['movieId'] == id].unique().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "für den Film Toy Story scheinen die Empfehlungen alle Filme aus den 90er Jahren zu sein, was logisch erscheint\n",
    "\n",
    "wir könnten auch andere Abstandsmetriken neben *Kosinus* ausprobieren, wie *Manhattan* oder *Euklidisch*.\n",
    "\n",
    "*Kosinus* ist eine gute Metrik, wenn wir nicht die Größe der Vektoren für den Abstand in Betracht ziehen wollen, sondern eher die Richtung des Vektors\n",
    "\n",
    "Bei der Verwendung von *Manhattan*- oder *Euklidischen*-Distanzen ist es wichtig, die Daten vor ihrer Anwendung zu normalisieren, wenn die verschiedenen Parameter unserer Daten unterschiedliche Bereiche aufweisen.\n",
    "\n",
    "die beste Praxis in diesem Schritt zur Optimierung der Hyperparameter ist die Durchführung von Gittersuchen, insbesondere die zufällige Gittersuche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_titles = find_recommended_movies(1, sparse_matrix, movie_mapper, inv_movie_mapper, 10, metric='euclidean') \n",
    "movie_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aus den gefundenen Indizes müssen wir diese in die dazu passende movieId umwandeln \n",
    "print(f\"for the movie {movie_ratings_df['title'].loc[movie_ratings_df['movieId'] == 1].unique().item()}, the recommendations are:\")\n",
    "for id in movie_titles:\n",
    "    print(movie_ratings_df['title'].loc[movie_ratings_df['movieId'] == id].unique().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bei Verwendung des euklidischen Abstands ergeben sich einige verschiedene Filme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Schritt 6: Behandlung des Kaltstartproblems**\n",
    "\n",
    "Die kollaborative Filterung stützt sich ausschließlich auf die Interaktionen zwischen Nutzern und Objekten innerhalb der Nutzwertmatrix. Das Problem bei diesem Ansatz besteht darin, dass ein neuer Benutzer oder ein neues Element aus der Nutzenmatrix ausgeschlossen wird, sobald es einen solchen gibt. Dies ist als **Kaltstartproblem** bekannt. Die inhaltsbasierte Filterung ist eine Möglichkeit, dieses Problem zu umgehen, da sie sich auf die Erstellung von Empfehlungen auf der Grundlage von Benutzer- und Artikelmerkmalen konzentriert.\n",
    "\n",
    "Wir beginnen mit der Umwandlung einer *Genre*-Spalte in binäre Merkmale. Jedes Genre hat seine eigene Spalte und wird mit 1en und 0en gefüllt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(movies_path)\n",
    "movies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres = movies_df['genres'].str.get_dummies(sep='|')\n",
    "movie_genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_genres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_sim = cosine_similarity(movie_genres)\n",
    "print(f\"Dimensions of our genres cosine similarity matrix: {cosine_sim.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die *cosine_similarity* ermittelt einen Wert zwischen 0 und 1, der angibt, wie ähnlich jede Zeile der einen Matrix den anderen Zeilen der zweiten Matrix ist.\n",
    "\n",
    "1 bedeutet identisch und 0 ist völlig unterschiedlich. \n",
    "\n",
    "Da wir ursprünglich 9742 Filme haben, ist es richtig, dass die Form dieser Matrix wie folgt aussehen würde $(n_{\\text{movies}}, n_{\\text{movies}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Erstellen einer Filmfindungsfunktion\n",
    "\n",
    "Wenn wir Filmempfehlungen ähnlich wie Jumanji erhalten möchten, müssen wir den genauen Titel kennen, wie er in unserem Datensatz erscheint. Jumanji ist zum Beispiel als „Jumanji (1995)“ aufgeführt. Wenn wir ihn falsch schreiben oder das Erscheinungsjahr vergessen, erkennt der Empfehlungsgeber den Film nicht.\n",
    "\n",
    "Um es den Nutzern leichter zu machen, können wir das Python-Paket fuzzywuzzy verwenden. Es hilft dabei, den Titel zu finden, der am ehesten mit einer vom Benutzer eingegebenen Zeichenkette übereinstimmt. Wir werden eine Funktion, movie_finder(), erstellen, die fuzzywuzzy's String-Matching verwendet, um die beste Übereinstimmung für den Eingabetitel vorzuschlagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import process\n",
    "\n",
    "def movie_finder(title):\n",
    "    all_movies = movies_df['title'].tolist()\n",
    "    closest_match = process.extractOne(title, all_movies)\n",
    "    return closest_match[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test mit jumanji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = movie_finder('jumaidi')\n",
    "title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "um eine Empfehlung zu erhalten, erstellen wir einen Film-Mapper für den Index in der Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_idx = dict(zip(movies_df['title'], list(movies_df.index)))\n",
    "idx = movie_idx[title]\n",
    "print(f\"movie index for Jumanji: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir erstellen eine Funktion, um die Empfehlungen für einen bestimmten Film zu erhalten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_movies(movieTitle, n_recommendations=10):\n",
    "    title = movie_finder(movieTitle)\n",
    "    idx = movie_idx[title]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x : x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:n_recommendations+1]\n",
    "    similar_movies = [i[0] for i in sim_scores]\n",
    "    print(f\"because you watched {title}\")\n",
    "    print(movies_df['title'].iloc[similar_movies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_similar_movies('Toy story', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Schritt 7: Matrixfaktorisierung zur Dimensionalitätsreduktion**\n",
    "\n",
    "Die Matrixfaktorisierung (MF) ist ein Verfahren der linearen Algebra, mit dem latente Merkmale entdeckt werden können, die den Interaktionen zwischen Nutzern und Filmen zugrunde liegen. Diese latenten Merkmale ermöglichen eine kompaktere Darstellung der Vorlieben der Nutzer und der Objektbeschreibungen. MF ist besonders nützlich für sehr spärliche Daten und kann die Qualität von Empfehlungen verbessern. Der Algorithmus funktioniert durch Faktorisierung der ursprünglichen Benutzer-Element-Matrix in zwei Faktormatrizen:\n",
    "\n",
    "- Benutzer-Faktor-Matrix (n_Nutzer, k)\n",
    "- Artikel-Faktor-Matrix (k, n_Einzelteile)\n",
    "\n",
    "Wir reduzieren die Dimensionen unserer ursprünglichen Matrix auf „Geschmacks“-Dimensionen. Wir können die genaue Bedeutung der einzelnen latenten Merkmale *k* nicht interpretieren. Wir können uns jedoch mögliche Bedeutungen für sie vorstellen, z. B. könnte ein Merkmal für Nutzer stehen, die Comedy-Action-Filme aus den frühen 2000er Jahren mögen, während ein anderes für Bollywood-Filme aus den 90er Jahren stehen könnte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=20, n_iter=10)\n",
    "Q = svd.fit_transform(sparse_matrix.T)\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_id = 1\n",
    "recommended_movies = find_recommended_movies(movieId=movie_id, sparseMatrix=Q.T, movieMapper=movie_mapper, invMovieMapper=inv_movie_mapper, metric='cosine', k=10)\n",
    "\n",
    "print(f\"for the movie {movie_ratings_df['title'].loc[movie_ratings_df['movieId'] == movie_id].unique().item()}, the recommendations are:\")\n",
    "for id in recommended_movies:\n",
    "    print(movie_ratings_df['title'].loc[movie_ratings_df['movieId'] == id].unique().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse sind ähnlich wie bei einem KNN-Modell, es scheinen durchweg Filme aus den 90er Jahren zu sein, einschließlich einiger früherer Kinderfilme"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movieRecommender_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
